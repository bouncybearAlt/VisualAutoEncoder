{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b972149b-bd46-484b-85ee-34bafd70d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataset.interface import SITE_DATASET_DIR\n",
    "\n",
    "site_options = os.listdir(SITE_DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8ec78b-4f6b-4b2c-ba74-e24e2bc54f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.interface import Site\n",
    "\n",
    "site = Site(site_options[0])\n",
    "groups = list(site)\n",
    "images = {group.name: list(group) for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3124d92-2b5a-4652-b8e9-db5eac19fc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4647"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.pytorch import ImageDataset, collate_largest\n",
    "images_dataset = ImageDataset(images)\n",
    "len(images_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db2ecd9-99de-4c2b-a62d-f6b222fba838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, ConvTranspose2d, ReLU, MaxPool2d\n",
    "class Encoder(Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1,2,5,)\n",
    "        self.conv2 = Conv2d(2,4,5,) \n",
    "        self.activation1 = ReLU()\n",
    "        self.max_pool1 = MaxPool2d(2)\n",
    "        self.conv3 = Conv2d(4,8,5,)\n",
    "        self.conv4 = Conv2d(8,16,5,)\n",
    "        self.activation2 = ReLU()\n",
    "        self.max_pool2 = MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.deconv1 = ConvTranspose2d(16,8,4,stride=1)\n",
    "        self.deconv2 = ConvTranspose2d(8,4,4,stride=2)\n",
    "        self.activation1 = ReLU()\n",
    "        self.deconv3 = ConvTranspose2d(4,2,4,stride=1)\n",
    "        self.deconv4 = ConvTranspose2d(2,1,4,stride=2)\n",
    "        self.activation2 = ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.deconv4(x)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "class Autoencoder(Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f71859-9dea-476a-80a4-510ad4c1084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "\n",
    "split = [int(len(images_dataset)*f) for f in [0.5,0.1,0.4]]\n",
    "split[0] += len(images_dataset) - sum(split)\n",
    "train_images, valid_images, test_images = random_split(images_dataset, split)\n",
    "    \n",
    "batch_size = 16\n",
    "autoencoder = Autoencoder(Encoder(),Decoder())\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(autoencoder.parameters(),lr=.001,eps=1e-4)\n",
    "dataloader = DataLoader(train_images, batch_size=batch_size, shuffle=True, collate_fn=collate_largest(4,4), num_workers=4, prefetch_factor=2, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_images, batch_size=batch_size, collate_fn=collate_largest(4,4), num_workers=4, prefetch_factor=2, pin_memory=True)\n",
    "epochs=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6afbd3-92bc-4524-94f4-7496ef0e60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isfile(\"last.model\"):\n",
    "    autoencoder.load_state_dict(torch.load(\"last.model\"))\n",
    "autoencoder = autoencoder.to(memory_format=torch.channels_last).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76f9a00-4893-4f76-aaf3-8911ab570ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 157754.97888183594 Epoch Time 857.5731198787689\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import Output, Label\n",
    "import time\n",
    "\n",
    "accumulation_steps = 4\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    start_epoch = time.time()\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(memory_format=torch.channels_last).to(\"cuda\")\n",
    "        out = autoencoder(batch)\n",
    "        loss = criterion(out, batch) /accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if (i+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            train_loss += loss.item()\n",
    "    print(\"Loss:\", train_loss, \"Epoch Time\", time.time() - start_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0579f61d47a7837bd0bdbcde0b7dd36d001308017195eb3ad3e657a48ce9658c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
